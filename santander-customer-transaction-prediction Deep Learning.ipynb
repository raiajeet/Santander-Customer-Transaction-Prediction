{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### santander-customer-transaction-prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Artificial Neural Network has been implemented using Keras and Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\AJIT\\\\Desktop\\\\santander-customer-transaction-prediction\\\\train.csv\")\n",
    "df_test = pd.read_csv(\"C:\\\\Users\\\\AJIT\\\\Desktop\\\\santander-customer-transaction-prediction\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 201)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df['Type']='Train'\n",
    "df_test['Type']='Test'\n",
    "data = pd.concat([df,df_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_col = ['ID_code']\n",
    "target_col = [\"target\"]\n",
    "other_col=['Type'] #Test and Train Data set identifier\n",
    "num_cols= list(set(list(data.columns))-set(ID_col)-set(target_col)-set(other_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#Target variable is also a categorical so convert it\n",
    "data[\"target\"] =data[\"target\"].astype('str')\n",
    "\n",
    "train=data[data['Type']=='Train']\n",
    "test=data[data['Type']=='Test']\n",
    "\n",
    "train['is_train'] = np.random.uniform(0, 1, len(train)) <= .75\n",
    "Train, Validate = train[train['is_train']==True], train[train['is_train']==False]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(set(list(data.columns))-set(ID_col)-set(target_col)-set(other_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = Train[list(features)].values\n",
    "y_train = Train[\"target\"].values\n",
    "x_validate = Validate[list(features)].values\n",
    "y_validate = Validate[\"target\"].values\n",
    "x_test=test[list(features)].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_validate = sc.transform(x_validate)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "def auc(y_train, y_validate):\n",
    "    auc = tf.metrics.auc(y_train, y_validate)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=[auc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the ANN to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150268/150268 [==============================] - 12s 81us/step - loss: 0.2538 - auc: 0.7931\n",
      "Epoch 2/100\n",
      "150268/150268 [==============================] - 8s 51us/step - loss: 0.2334 - auc: 0.8411\n",
      "Epoch 3/100\n",
      "150268/150268 [==============================] - 8s 51us/step - loss: 0.2266 - auc: 0.8496\n",
      "Epoch 4/100\n",
      "150268/150268 [==============================] - 8s 52us/step - loss: 0.2206 - auc: 0.8542\n",
      "Epoch 5/100\n",
      "150268/150268 [==============================] - 8s 52us/step - loss: 0.2146 - auc: 0.8580\n",
      "Epoch 6/100\n",
      "150268/150268 [==============================] - 8s 52us/step - loss: 0.2075 - auc: 0.8612\n",
      "Epoch 7/100\n",
      "150268/150268 [==============================] - 7s 46us/step - loss: 0.1999 - auc: 0.8647\n",
      "Epoch 8/100\n",
      "150268/150268 [==============================] - 7s 48us/step - loss: 0.1917 - auc: 0.8683\n",
      "Epoch 9/100\n",
      "150268/150268 [==============================] - 8s 52us/step - loss: 0.1835 - auc: 0.8721\n",
      "Epoch 10/100\n",
      "150268/150268 [==============================] - 8s 53us/step - loss: 0.1756 - auc: 0.8759\n",
      "Epoch 11/100\n",
      "150268/150268 [==============================] - 8s 52us/step - loss: 0.1674 - auc: 0.8800\n",
      "Epoch 12/100\n",
      "150268/150268 [==============================] - 8s 53us/step - loss: 0.1593 - auc: 0.8839\n",
      "Epoch 13/100\n",
      "150268/150268 [==============================] - 8s 53us/step - loss: 0.1517 - auc: 0.8880\n",
      "Epoch 14/100\n",
      "150268/150268 [==============================] - 8s 52us/step - loss: 0.1440 - auc: 0.8920\n",
      "Epoch 15/100\n",
      "150268/150268 [==============================] - 8s 53us/step - loss: 0.1372 - auc: 0.8960\n",
      "Epoch 16/100\n",
      "150268/150268 [==============================] - 8s 53us/step - loss: 0.1318 - auc: 0.8998\n",
      "Epoch 17/100\n",
      "150268/150268 [==============================] - 8s 53us/step - loss: 0.1247 - auc: 0.9035\n",
      "Epoch 18/100\n",
      "150268/150268 [==============================] - 8s 53us/step - loss: 0.1195 - auc: 0.9072\n",
      "Epoch 19/100\n",
      "150268/150268 [==============================] - 8s 53us/step - loss: 0.1140 - auc: 0.9107\n",
      "Epoch 20/100\n",
      "150268/150268 [==============================] - 9s 63us/step - loss: 0.1095 - auc: 0.9140\n",
      "Epoch 21/100\n",
      "150268/150268 [==============================] - 9s 57us/step - loss: 0.1048 - auc: 0.9172\n",
      "Epoch 22/100\n",
      "150268/150268 [==============================] - 8s 53us/step - loss: 0.1022 - auc: 0.9202\n",
      "Epoch 23/100\n",
      "150268/150268 [==============================] - 8s 53us/step - loss: 0.0967 - auc: 0.9231\n",
      "Epoch 24/100\n",
      "150268/150268 [==============================] - 8s 53us/step - loss: 0.0935 - auc: 0.9258\n",
      "Epoch 25/100\n",
      "150268/150268 [==============================] - 8s 55us/step - loss: 0.0905 - auc: 0.9284\n",
      "Epoch 26/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0872 - auc: 0.9308\n",
      "Epoch 27/100\n",
      "150268/150268 [==============================] - 9s 58us/step - loss: 0.0845 - auc: 0.9331\n",
      "Epoch 28/100\n",
      "150268/150268 [==============================] - 9s 59us/step - loss: 0.0811 - auc: 0.9353\n",
      "Epoch 29/100\n",
      "150268/150268 [==============================] - 9s 59us/step - loss: 0.0782 - auc: 0.9374\n",
      "Epoch 30/100\n",
      "150268/150268 [==============================] - 9s 58us/step - loss: 0.0769 - auc: 0.9394\n",
      "Epoch 31/100\n",
      "150268/150268 [==============================] - 9s 58us/step - loss: 0.0745 - auc: 0.9413\n",
      "Epoch 32/100\n",
      "150268/150268 [==============================] - 9s 63us/step - loss: 0.0720 - auc: 0.9431\n",
      "Epoch 33/100\n",
      "150268/150268 [==============================] - 9s 58us/step - loss: 0.0692 - auc: 0.9448\n",
      "Epoch 34/100\n",
      "150268/150268 [==============================] - 9s 61us/step - loss: 0.0682 - auc: 0.9465\n",
      "Epoch 35/100\n",
      "150268/150268 [==============================] - 9s 62us/step - loss: 0.0663 - auc: 0.9481\n",
      "Epoch 36/100\n",
      "150268/150268 [==============================] - 10s 63us/step - loss: 0.0647 - auc: 0.9496\n",
      "Epoch 37/100\n",
      "150268/150268 [==============================] - 10s 65us/step - loss: 0.0621 - auc: 0.9510\n",
      "Epoch 38/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0607 - auc: 0.9524\n",
      "Epoch 39/100\n",
      "150268/150268 [==============================] - 9s 63us/step - loss: 0.0585 - auc: 0.9537\n",
      "Epoch 40/100\n",
      "150268/150268 [==============================] - 8s 52us/step - loss: 0.0603 - auc: 0.9549\n",
      "Epoch 41/100\n",
      "150268/150268 [==============================] - 8s 51us/step - loss: 0.0579 - auc: 0.9561\n",
      "Epoch 42/100\n",
      "150268/150268 [==============================] - 7s 50us/step - loss: 0.0562 - auc: 0.9572\n",
      "Epoch 43/100\n",
      "150268/150268 [==============================] - 8s 52us/step - loss: 0.0541 - auc: 0.9583\n",
      "Epoch 44/100\n",
      "150268/150268 [==============================] - 8s 54us/step - loss: 0.0542 - auc: 0.9593\n",
      "Epoch 45/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0531 - auc: 0.9603\n",
      "Epoch 46/100\n",
      "150268/150268 [==============================] - 9s 57us/step - loss: 0.0524 - auc: 0.9613\n",
      "Epoch 47/100\n",
      "150268/150268 [==============================] - 8s 57us/step - loss: 0.0488 - auc: 0.9622\n",
      "Epoch 48/100\n",
      "150268/150268 [==============================] - 8s 57us/step - loss: 0.0525 - auc: 0.9631\n",
      "Epoch 49/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0505 - auc: 0.9639\n",
      "Epoch 50/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0471 - auc: 0.9647\n",
      "Epoch 51/100\n",
      "150268/150268 [==============================] - 9s 60us/step - loss: 0.0476 - auc: 0.9655\n",
      "Epoch 52/100\n",
      "150268/150268 [==============================] - 9s 60us/step - loss: 0.0488 - auc: 0.9662\n",
      "Epoch 53/100\n",
      "150268/150268 [==============================] - 8s 55us/step - loss: 0.0460 - auc: 0.9670\n",
      "Epoch 54/100\n",
      "150268/150268 [==============================] - 8s 55us/step - loss: 0.0445 - auc: 0.9677\n",
      "Epoch 55/100\n",
      "150268/150268 [==============================] - 8s 55us/step - loss: 0.0447 - auc: 0.9683\n",
      "Epoch 56/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0445 - auc: 0.9690\n",
      "Epoch 57/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0443 - auc: 0.9696\n",
      "Epoch 58/100\n",
      "150268/150268 [==============================] - 8s 55us/step - loss: 0.0445 - auc: 0.9702\n",
      "Epoch 59/100\n",
      "150268/150268 [==============================] - 8s 55us/step - loss: 0.0418 - auc: 0.9708\n",
      "Epoch 60/100\n",
      "150268/150268 [==============================] - 8s 55us/step - loss: 0.0422 - auc: 0.9713\n",
      "Epoch 61/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0440 - auc: 0.9718\n",
      "Epoch 62/100\n",
      "150268/150268 [==============================] - 9s 62us/step - loss: 0.0397 - auc: 0.9724\n",
      "Epoch 63/100\n",
      "150268/150268 [==============================] - 11s 73us/step - loss: 0.0389 - auc: 0.9729\n",
      "Epoch 64/100\n",
      "150268/150268 [==============================] - 10s 65us/step - loss: 0.0403 - auc: 0.9734\n",
      "Epoch 65/100\n",
      "150268/150268 [==============================] - 9s 60us/step - loss: 0.0411 - auc: 0.9739\n",
      "Epoch 66/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0384 - auc: 0.9743\n",
      "Epoch 67/100\n",
      "150268/150268 [==============================] - 9s 60us/step - loss: 0.0382 - auc: 0.9748\n",
      "Epoch 68/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0375 - auc: 0.9752\n",
      "Epoch 69/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0379 - auc: 0.9756\n",
      "Epoch 70/100\n",
      "150268/150268 [==============================] - 9s 59us/step - loss: 0.0388 - auc: 0.9760\n",
      "Epoch 71/100\n",
      "150268/150268 [==============================] - 9s 59us/step - loss: 0.0369 - auc: 0.9764\n",
      "Epoch 72/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0366 - auc: 0.9768\n",
      "Epoch 73/100\n",
      "150268/150268 [==============================] - 8s 56us/step - loss: 0.0351 - auc: 0.9772\n",
      "Epoch 74/100\n",
      "150268/150268 [==============================] - 9s 60us/step - loss: 0.0347 - auc: 0.9775\n",
      "Epoch 75/100\n",
      "150268/150268 [==============================] - 9s 58us/step - loss: 0.0380 - auc: 0.9779\n",
      "Epoch 76/100\n",
      "150268/150268 [==============================] - 9s 57us/step - loss: 0.0339 - auc: 0.9782\n",
      "Epoch 77/100\n",
      "150268/150268 [==============================] - 9s 62us/step - loss: 0.0355 - auc: 0.9785\n",
      "Epoch 78/100\n",
      "150268/150268 [==============================] - 10s 68us/step - loss: 0.0340 - auc: 0.9789\n",
      "Epoch 79/100\n",
      "150268/150268 [==============================] - 7s 49us/step - loss: 0.0332 - auc: 0.9792\n",
      "Epoch 80/100\n",
      "150268/150268 [==============================] - 7s 49us/step - loss: 0.0357 - auc: 0.9795\n",
      "Epoch 81/100\n",
      "150268/150268 [==============================] - 7s 49us/step - loss: 0.0325 - auc: 0.9798\n",
      "Epoch 82/100\n",
      "150268/150268 [==============================] - 7s 49us/step - loss: 0.0349 - auc: 0.9801\n",
      "Epoch 83/100\n",
      "150268/150268 [==============================] - 7s 49us/step - loss: 0.0322 - auc: 0.9803\n",
      "Epoch 84/100\n",
      "150268/150268 [==============================] - 8s 52us/step - loss: 0.0327 - auc: 0.9806\n",
      "Epoch 85/100\n",
      "150268/150268 [==============================] - 7s 49us/step - loss: 0.0331 - auc: 0.9809\n",
      "Epoch 86/100\n",
      "150268/150268 [==============================] - 7s 50us/step - loss: 0.0320 - auc: 0.9812\n",
      "Epoch 87/100\n",
      "150268/150268 [==============================] - 7s 50us/step - loss: 0.0312 - auc: 0.9814\n",
      "Epoch 88/100\n",
      "150268/150268 [==============================] - 7s 50us/step - loss: 0.0311 - auc: 0.9817\n",
      "Epoch 89/100\n",
      "150268/150268 [==============================] - 7s 50us/step - loss: 0.0317 - auc: 0.9819\n",
      "Epoch 90/100\n",
      "150268/150268 [==============================] - 7s 50us/step - loss: 0.0325 - auc: 0.9821\n",
      "Epoch 91/100\n",
      "150268/150268 [==============================] - 8s 50us/step - loss: 0.0299 - auc: 0.9824\n",
      "Epoch 92/100\n",
      "150268/150268 [==============================] - 8s 51us/step - loss: 0.0300 - auc: 0.9826\n",
      "Epoch 93/100\n",
      "150268/150268 [==============================] - 8s 50us/step - loss: 0.0319 - auc: 0.9828\n",
      "Epoch 94/100\n",
      "150268/150268 [==============================] - 7s 50us/step - loss: 0.0294 - auc: 0.9830\n",
      "Epoch 95/100\n",
      "150268/150268 [==============================] - 9s 60us/step - loss: 0.0283 - auc: 0.9833\n",
      "Epoch 96/100\n",
      "150268/150268 [==============================] - 12s 78us/step - loss: 0.0309 - auc: 0.9835 3s - \n",
      "Epoch 97/100\n",
      "150268/150268 [==============================] - 11s 71us/step - loss: 0.0307 - auc: 0.9837\n",
      "Epoch 98/100\n",
      "150268/150268 [==============================] - 10s 64us/step - loss: 0.0283 - auc: 0.9838\n",
      "Epoch 99/100\n",
      "150268/150268 [==============================] - 11s 71us/step - loss: 0.0275 - auc: 0.9840\n",
      "Epoch 100/100\n",
      "150268/150268 [==============================] - 10s 65us/step - loss: 0.0295 - auc: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c6bddcaba8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train, y_train, batch_size = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.639\n"
     ]
    }
   ],
   "source": [
    "probs = classifier.predict_proba(x_validate)\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_validate, probs)\n",
    "print('AUC: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing, feature engineering, data analysis, Cross Validation, and hyperparameter tuning avoided due to less computing resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
